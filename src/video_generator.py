# -*- coding: utf-8 -*-
"""Video Generator.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OlE8yLx3aLPhpDg-aCWzMiaqpTEWb_bq
"""

!pip install diffusers
!pip install transformers
!pip install accelerate
!pip install opencv-python
!pip install pillow
!pip install matplotlib

from diffusers import DiffusionPipeline
import torch

print("Loading the model, this may take a few minutes...")
pipe = DiffusionPipeline.from_pretrained("cerspense/zeroscope_v2_576w", torch_dtype=torch.float16)
pipe.to("cuda")  # Use GPU for faster generation
print("Model loaded successfully!")

prompt = input("Enter a prompt for the video (e.g., 'A futuristic city at sunset with flying cars'): ")

# Step 4: Generate the Video Frames
print(f"Generating video for the prompt: '{prompt}'")
video_frames = pipe(
    prompt=prompt,
    num_frames=24,           # Number of frames (1 second @ 24 FPS)
    height=320,              # Resolution height
    width=576,               # Resolution width
    num_inference_steps=50   # Quality of generated video
).frames  # This returns a batch of frames (shape: [num_frames, height, width, 3])

print("Video frames generated!")

# Debug Step 1: Verify Frames
print(f"Number of frames generated in batch: {video_frames[0].shape[0]}")
for i in range(video_frames[0].shape[0]):
    frame = video_frames[0][i]
    print(f"Frame {i} stats - dtype: {frame.dtype}, shape: {frame.shape}, min: {frame.min()}, max: {frame.max()}")

# Debug Step 2: Display the First Frame
from matplotlib import pyplot as plt

first_frame = video_frames[0][0]  # Extract the first frame from the batch
plt.imshow(first_frame)
plt.title("First Frame")
plt.axis("off")
plt.show()

# Step 5: Convert Frames to Video and Display in Colab
import cv2
import numpy as np
from IPython.display import HTML, display
import base64

# Save frames as a video
output_path = "generated_video.mp4"
fps = 24
frame_size = (video_frames[0][0].shape[1], video_frames[0][0].shape[0])  # Width and height from numpy array
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out = cv2.VideoWriter(output_path, fourcc, fps, frame_size)

# Debug Step 3: Verify VideoWriter Initialization
assert out.isOpened(), "VideoWriter failed to initialize"

# Write each frame into the video
for frame in video_frames[0]:  # Iterate over each frame in the batch
    frame_uint8 = (frame * 255).astype('uint8')  # Convert float32 [0, 1] to uint8 [0, 255]
    frame_bgr = cv2.cvtColor(frame_uint8, cv2.COLOR_RGB2BGR)  # Convert RGB to BGR for OpenCV
    out.write(frame_bgr)

out.release()

print(f"Video saved as {output_path}")

# Display video in the notebook
def show_video(video_path, width=576):
    video_data = open(video_path, "rb").read()
    video_encoded = base64.b64encode(video_data).decode("ascii")
    video_html = f"""
    <video width="{width}" controls>
        <source src="data:video/mp4;base64,{video_encoded}" type="video/mp4">
        Your browser does not support the video tag.
    </video>
    """
    display(HTML(video_html))

show_video(output_path)

# Step 6: Option to Download the Video
from google.colab import files
files.download(output_path)